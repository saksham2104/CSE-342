{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc50f38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dataset \n",
    "\n",
    "x = np.random.uniform(0, 1, 100)\n",
    "epsilon = np.random.normal(0, 0.01, 100)\n",
    "\n",
    "D = []\n",
    "\n",
    "for i in range (100):\n",
    "    D.append((x[i],np.sin(2*np.pi*x[i]) + np.cos(2*np.pi*x[i]) + epsilon[i]))\n",
    "\n",
    "D_train = D[:80]\n",
    "D_test = D[80:]\n",
    "\n",
    "x_train,y_train,x_test,y_test = [],[],[],[]\n",
    "\n",
    "for i in range(100):\n",
    "    if i < 80:\n",
    "        x_train.append(D[i][0])\n",
    "        y_train.append(D[i][1])\n",
    "    else:\n",
    "        x_test.append(D[i][0])\n",
    "        y_test.append(D[i][1])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#Gradient Boosting\n",
    "\n",
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        self.left_value = None\n",
    "        self.right_value = None\n",
    "\n",
    "    def fit(self, x, residuals, flag):\n",
    "        thresholds = np.linspace(0, 1, 20)\n",
    "        min_loss = float('inf')\n",
    "\n",
    "        for thresh in thresholds:\n",
    "            left_mask = x <= thresh\n",
    "            right_mask = x > thresh\n",
    "\n",
    "            if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            left_pred = np.mean(residuals[left_mask])\n",
    "            right_pred = np.mean(residuals[right_mask])\n",
    "\n",
    "            predictions = np.where(x <= thresh, left_pred, right_pred)\n",
    "\n",
    "            if flag == 0:\n",
    "                curr_loss = np.mean((residuals - predictions) ** 2)\n",
    "            elif flag == 1:\n",
    "                curr_loss = np.mean(np.abs(residuals - predictions))\n",
    "            \n",
    "            if curr_loss < min_loss:\n",
    "                min_loss = curr_loss\n",
    "                self.threshold = thresh\n",
    "                self.left_value = left_pred\n",
    "                self.right_value = right_pred\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.where(x <= self.threshold, self.left_value, self.right_value)\n",
    "\n",
    "rho = 0.01\n",
    "F_train = np.full(len(x_train), np.mean(y_train))\n",
    "F_test = np.full(len(x_test), np.mean(y_train))\n",
    "\n",
    "F_train_1 = np.full(len(x_train), np.mean(y_train))\n",
    "F_test_1 = np.full(len(x_test), np.mean(y_train))\n",
    "\n",
    "train_predictions = [F_train.copy()]\n",
    "test_predictions = [F_test.copy()]\n",
    "train_losses = []\n",
    "\n",
    "train_predictions_1 = [F_train_1.copy()]\n",
    "test_predictions_1 = [F_test_1.copy()]\n",
    "train_losses_1 = []\n",
    "\n",
    "for t in range(500):\n",
    "    # Compute negative gradients (residuals)\n",
    "    residuals = y_train - F_train\n",
    "    residuals_1 = np.sign(y_train - F_train_1)\n",
    "\n",
    "    # Fit decision stumps to residuals\n",
    "    stump = DecisionStump()\n",
    "    stump.fit(x_train, residuals ,0)\n",
    "\n",
    "    stump_1 = DecisionStump()\n",
    "    stump_1.fit(x_train, residuals_1,1)\n",
    "\n",
    "    # Gradient descent step\n",
    "    update = stump.predict(x_train)\n",
    "    update_1 = stump_1.predict(x_train)\n",
    "    F_train += rho * update\n",
    "    F_train_1 += rho * update_1\n",
    "\n",
    "    # Predict on test set\n",
    "    update_test = stump.predict(x_test)\n",
    "    update_test_1 = stump_1.predict(x_test)\n",
    "    F_test += rho * update_test\n",
    "    F_test_1 += rho * update_test_1\n",
    "\n",
    "    # Store predictions and losses\n",
    "    train_predictions.append(F_train.copy())\n",
    "    test_predictions.append(F_test.copy())\n",
    "    train_predictions_1.append(F_train_1.copy())\n",
    "    test_predictions_1.append(F_test_1.copy())\n",
    "\n",
    "    loss = np.mean((y_train - F_train) ** 2)\n",
    "    loss_1 = np.mean(np.abs(y_train - F_train_1))\n",
    "    train_losses.append(loss)\n",
    "    train_losses_1.append(loss_1)\n",
    "\n",
    "#  Plot Predictions vs Ground Truth\n",
    "iterations_to_plot = [0,100,200,300,400,499]  # selected iterations for visualization\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Squared Loss - Train Predictions\n",
    "for i, it in enumerate(iterations_to_plot):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.scatter(x_train, y_train, color='black', label='Ground Truth', alpha=0.6)\n",
    "    plt.scatter(x_train, train_predictions[it], color='red', label=f'Predicted (Iter {it})', alpha=0.6)\n",
    "    plt.title(f'Train (Squared Loss) - Iter {it}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Squared Loss - Test Predictions\n",
    "for i, it in enumerate(iterations_to_plot):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.scatter(x_test, y_test, color='black', label='Ground Truth', alpha=0.6)\n",
    "    plt.scatter(x_test, test_predictions[it], color='blue', label=f'Predicted (Iter {it})', alpha=0.6)\n",
    "    plt.title(f'Test (Squared Loss) - Iter {it}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Absolute Loss - Train Predictions\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, it in enumerate(iterations_to_plot):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.scatter(x_train, y_train, color='black', label='Ground Truth', alpha=0.6)\n",
    "    plt.scatter(x_train, train_predictions_1[it], color='green', label=f'Predicted (Iter {it})', alpha=0.6)\n",
    "    plt.title(f'Train (Absolute Loss) - Iter {it}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Absolute Loss - Test Predictions\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, it in enumerate(iterations_to_plot):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.scatter(x_test, y_test, color='black', label='Ground Truth', alpha=0.6)\n",
    "    plt.scatter(x_test, test_predictions_1[it], color='purple', label=f'Predicted (Iter {it})', alpha=0.6)\n",
    "    plt.title(f'Test (Absolute Loss) - Iter {it}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# 2. Plot Training Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Squared Loss', color='red')\n",
    "plt.plot(train_losses_1, label='Absolute Loss', color='green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
