{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, f=None, t=None, l=None, r=None, v=None):\n",
    "        self.feature = f\n",
    "        self.threshold = t\n",
    "        self.left = l\n",
    "        self.right = r\n",
    "        self.value = v\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_d=4, min_s=1, feat_sub=None):\n",
    "        self.max_depth = max_d\n",
    "        self.min_samples = min_s\n",
    "        self.root = None\n",
    "        self.feature_subset = feat_sub #for RF\n",
    "\n",
    "    #gini impurity\n",
    "    def gini(self, y):\n",
    "        cls , cnt = np.unique(y, return_counts=True)\n",
    "        probs = cnt / cnt.sum()\n",
    "        return 1 - np.sum(probs ** 2)\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_g = float('inf')\n",
    "        best_f, best_t = None, None\n",
    "        n, m = X.shape\n",
    "\n",
    "        if self.feature_subset and self.feature_subset < m:\n",
    "            feats = np.random.choice(m, self.feature_subset, replace=False) #dont repeat same feature twice\n",
    "        else:\n",
    "            feats = range(m)\n",
    "\n",
    "        for f in feats:\n",
    "            vals = np.unique(X[:, f])\n",
    "            for t in vals:\n",
    "                l_mask = X[:, f] == t\n",
    "                r_mask = ~l_mask\n",
    "\n",
    "                if sum(l_mask) == 0 or sum(r_mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                #training on gini\n",
    "                g_l = self.gini(y[l_mask])\n",
    "                g_r = self.gini(y[r_mask])\n",
    "                g_split = (sum(l_mask) * g_l + sum(r_mask) * g_r) / n\n",
    "\n",
    "                if g_split < best_g:\n",
    "                    best_g = g_split\n",
    "                    best_f = f\n",
    "                    best_t = t\n",
    "\n",
    "        return best_f, best_t\n",
    "\n",
    "    def build(self, X, y, d=0):\n",
    "        n, m = X.shape\n",
    "        cls = np.unique(y)\n",
    "\n",
    "        #stopping conditions\n",
    "        if d >= self.max_depth or n < self.min_samples or len(cls) == 1:\n",
    "            leaf = cls[0] if len(cls) == 1 else max(cls, key=list(y).count)\n",
    "            return Node(v=leaf)\n",
    "\n",
    "        f, t = self.best_split(X, y)\n",
    "\n",
    "        if f is None:\n",
    "            return Node(v=max(cls, key=list(y).count))\n",
    "\n",
    "        l_mask = X[:, f] == t\n",
    "        r_mask = ~l_mask\n",
    "\n",
    "        #recursive method\n",
    "        l_sub = self.build(X[l_mask], y[l_mask], d + 1)\n",
    "        r_sub = self.build(X[r_mask], y[r_mask], d + 1)\n",
    "\n",
    "        return Node(f=f, t=t, l=l_sub, r=r_sub)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build(X, y)\n",
    "\n",
    "    def pred_sample(self, node, x):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] == node.threshold:\n",
    "            return self.pred_sample(node.left, x)\n",
    "        else:\n",
    "            return self.pred_sample(node.right, x)\n",
    "    #prediciton\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            preds.append(self.pred_sample(self.root, x))\n",
    "        return np.array(preds)\n",
    "\n",
    "class Bagging:\n",
    "    #bagging of 10 trees\n",
    "    def __init__(self, n_trees=10, max_d=4, min_s=1, feat_sub=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_d\n",
    "        self.min_samples = min_s\n",
    "        self.trees = []\n",
    "        self.feature_subset = feat_sub #for RF\n",
    "        self.oob_idx = []\n",
    "\n",
    "    def bootstrap(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        idx = np.random.choice(n, n, replace=True) #with replacement\n",
    "        oob_mask = np.ones(n, dtype=bool)\n",
    "        oob_mask[idx] = False\n",
    "        oob = np.where(oob_mask)[0]\n",
    "        return X[idx], y[idx], oob\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        self.oob_idx = []\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            X_b, y_b, oob = self.bootstrap(X, y)\n",
    "            self.oob_idx.append(oob)\n",
    "\n",
    "            tree = DecisionTree(max_d=self.max_depth, min_s=self.min_samples, feat_sub=self.feature_subset)\n",
    "            tree.fit(X_b, y_b)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        final = []\n",
    "        for i in range(X.shape[0]):\n",
    "            preds = [tree.pred_sample(tree.root, X[i]) for tree in self.trees]\n",
    "            pred = Counter(preds).most_common(1)[0][0]\n",
    "            final.append(pred)\n",
    "        return np.array(final)\n",
    "\n",
    "    #oob_error\n",
    "    def oob_error(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        oob_preds = np.zeros((n, self.n_trees), dtype=int)\n",
    "        oob_counts = np.zeros(n, dtype=int)\n",
    "\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            oob = self.oob_idx[i]\n",
    "            if len(oob) > 0:\n",
    "                preds = tree.predict(X[oob])\n",
    "                for j, idx in enumerate(oob):\n",
    "                    oob_preds[idx, oob_counts[idx]] = preds[j]\n",
    "                    oob_counts[idx] += 1\n",
    "\n",
    "        final_preds = np.zeros(n, dtype=int)\n",
    "        for i in range(n):\n",
    "            if oob_counts[i] > 0:\n",
    "                votes = oob_preds[i, :oob_counts[i]]\n",
    "                final_preds[i] = Counter(votes).most_common(1)[0][0]\n",
    "\n",
    "        valid = oob_counts > 0\n",
    "        return np.sum(final_preds[valid] != y[valid]) / sum(valid)\n",
    "\n",
    "# Data\n",
    "data = [\n",
    "    (25, \"High\", \"No\", \"Fair\", \"No\"),\n",
    "    (30, \"High\", \"No\", \"Excellent\", \"No\"),\n",
    "    (35, \"Medium\", \"No\", \"Fair\", \"Yes\"),\n",
    "    (40, \"Low\", \"No\", \"Fair\", \"Yes\"),\n",
    "    (45, \"Low\", \"Yes\", \"Fair\", \"Yes\"),\n",
    "    (50, \"Low\", \"Yes\", \"Excellent\", \"No\"),\n",
    "    (55, \"Medium\", \"Yes\", \"Excellent\", \"Yes\"),\n",
    "    (60, \"High\", \"No\", \"Fair\", \"No\")\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Age\", \"Income\", \"Student\", \"Credit\", \"Buy\"])\n",
    "df[\"Buy\"] = df[\"Buy\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df[\"Income\"] = df[\"Income\"].map({\"High\": 0, \"Medium\": 1, \"Low\": 2})\n",
    "df[\"Student\"] = df[\"Student\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df[\"Credit\"] = df[\"Credit\"].map({\"Fair\": 0, \"Excellent\": 1})\n",
    "\n",
    "X = df.drop(columns=[\"Buy\"]).values\n",
    "y = df[\"Buy\"].values\n",
    "\n",
    "new_x = np.array([[42, 2, 0, 1]])\n",
    "\n",
    "print(\"\\n----- Q3: Single Decision Tree -----\")\n",
    "tree = DecisionTree(max_d=3, min_s=1)\n",
    "tree.fit(X, y)\n",
    "pred = tree.predict(new_x)\n",
    "print(\"Single Tree Prediction:\", \"Yes\" if pred[0] == 1 else \"No\")\n",
    "\n",
    "print(\"\\n----- Q4: Bagging with 10 trees -----\")\n",
    "bag = Bagging(n_trees=10, max_d=3, min_s=1)\n",
    "bag.fit(X, y)\n",
    "bag_pred = bag.predict(new_x)\n",
    "print(\"Bagging Prediction:\", \"Yes\" if bag_pred[0] == 1 else \"No\")\n",
    "\n",
    "oob_err_bag = bag.oob_error(X, y)\n",
    "print(f\"Bagging OOB Error: {oob_err_bag:.4f}\")\n",
    "\n",
    "print(\"\\n----- Q4: Random Forest with 2 random predictors -----\")\n",
    "rf = Bagging(n_trees=10, max_d=3, min_s=1, feat_sub=2)\n",
    "rf.fit(X, y)\n",
    "rf_pred = rf.predict(new_x)\n",
    "print(\"Random Forest Prediction:\", \"Yes\" if rf_pred[0] == 1 else \"No\")\n",
    "\n",
    "oob_err_rf = rf.oob_error(X, y)\n",
    "print(f\"Random Forest OOB Error: {oob_err_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Q-5 -> 5 fold cross validation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "n = 100\n",
    "x = np.random.uniform(0, 2*np.pi, n)\n",
    "y_true = np.sin(x)\n",
    "noise = np.random.normal(0, 0.1, n)\n",
    "y = y_true + noise\n",
    " \n",
    "def poly_features(x, d):\n",
    "    x_poly = np.ones((len(x), d + 1))\n",
    "    for i in range(len(x)):  \n",
    "        for j in range(1, d + 1):  \n",
    "            x_poly[i][j] = x_poly[i][j - 1]*x[i]  \n",
    "\n",
    "    return x_poly\n",
    "\n",
    "\n",
    "def lin_reg(x, y):\n",
    "    matrice_A=x.T @ x\n",
    "    det_a=np.linalg.det(matrice_A)\n",
    "    if(det_a == 0):\n",
    "        return np.linalg.pinv(x.T @ x)@ x.T @ y \n",
    "    return np.linalg.inv(x.T @ x)@ x.T @ y \n",
    "\n",
    "def predict(x, w):\n",
    "    return x @ w\n",
    "\n",
    "def mse(y, y_pred):\n",
    "    return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "#  Split data\n",
    "def k_fold(n):\n",
    "    k=5\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    fold_sz = [20]*5\n",
    "    \n",
    "    folds = []\n",
    "    start = 0\n",
    "    for size in fold_sz:\n",
    "        test_idx = idx[start:start + size]\n",
    "        train_idx = np.concatenate((idx[:start], idx[start + size:]))\n",
    "        folds.append((train_idx, test_idx))\n",
    "        start += size\n",
    "    \n",
    "    return folds\n",
    "\n",
    "degrees = [1, 2, 3, 4]\n",
    "k = 5\n",
    "cv_scores = {}\n",
    "train_scores = {}\n",
    "\n",
    "\n",
    "for d in degrees: \n",
    "    test_mses = []\n",
    "    train_mses = []\n",
    "    \n",
    "    for train_idx, test_idx in k_fold(n):\n",
    "        x_train, x_test = x[train_idx], x[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        x_train_poly = poly_features(x_train, d)\n",
    "        x_test_poly = poly_features(x_test, d)\n",
    "        \n",
    "        w = lin_reg(x_train_poly, y_train)\n",
    "        \n",
    "        y_train_pred = predict(x_train_poly, w)\n",
    "        y_test_pred = predict(x_test_poly, w)\n",
    "        \n",
    "        train_mses.append(mse(y_train, y_train_pred))\n",
    "        test_mses.append(mse(y_test, y_test_pred))\n",
    "    \n",
    "    cv_scores[d] = np.mean(test_mses)\n",
    "    train_scores[d] = np.mean(train_mses)\n",
    "\n",
    "best_d = 1\n",
    "mini = 1000000 \n",
    "\n",
    "for d in cv_scores:\n",
    "    if cv_scores[d] < mini:\n",
    "        mini = cv_scores[d]\n",
    "        best_d = d\n",
    "\n",
    "\n",
    "print(\"Train & Test MSE for each degree:\")\n",
    "for d in degrees:\n",
    "    print(f\"Degree {d}: Train MSE = {train_scores[d]:.6f}, Test MSE = {cv_scores[d]:.6f}\")\n",
    "\n",
    "print(f\"\\nBest degree: {best_d}\")\n",
    "\n",
    "\n",
    "x_poly = poly_features(x, best_d)\n",
    "w_best = lin_reg(x_poly, y)\n",
    "\n",
    "\n",
    "x_plot = np.linspace(0, 2*np.pi, 1000)\n",
    "y_plot = np.sin(x_plot)\n",
    "x_plot_poly = poly_features(x_plot, best_d)\n",
    "y_pred_plot = predict(x_plot_poly, w_best)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, color='blue', alpha=0.5, label='Noisy Data')\n",
    "plt.plot(x_plot, y_plot, color='green', label='True Function')\n",
    "plt.plot(x_plot, y_pred_plot, color='red', linestyle='--', label=f'Poly (degree {best_d})')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(f'Polynomial Regression (Best: deg {best_d})')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
